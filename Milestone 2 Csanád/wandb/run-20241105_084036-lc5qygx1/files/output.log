DistilBertForQuestionAnswering(
  (distilbert): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): DistilBertSdpaAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
            (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
            (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
            (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
            (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
DistilBertModel(
  (embeddings): Embeddings(
    (word_embeddings): Embedding(30522, 768, padding_idx=0)
    (position_embeddings): Embedding(512, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer): Transformer(
    (layer): ModuleList(
      (0-5): 6 x TransformerBlock(
        (attention): DistilBertSdpaAttention(
          (dropout): Dropout(p=0.1, inplace=False)
          (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
          (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
          (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
          (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
        )
        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (ffn): FFN(
          (dropout): Dropout(p=0.1, inplace=False)
          (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
          (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
          (activation): GELUActivation()
        )
        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
    )
  )
)
Embeddings(
  (word_embeddings): Embedding(30522, 768, padding_idx=0)
  (position_embeddings): Embedding(512, 768)
  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
Embedding(30522, 768, padding_idx=0)
Embedding(512, 768)
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
Dropout(p=0.1, inplace=False)
Transformer(
  (layer): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attention): DistilBertSdpaAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
        (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
        (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
        (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
      )
      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (ffn): FFN(
        (dropout): Dropout(p=0.1, inplace=False)
        (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
        (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
        (activation): GELUActivation()
      )
      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    )
  )
)
ModuleList(
  (0-5): 6 x TransformerBlock(
    (attention): DistilBertSdpaAttention(
      (dropout): Dropout(p=0.1, inplace=False)
      (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
      (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
      (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
      (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    )
    (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    (ffn): FFN(
      (dropout): Dropout(p=0.1, inplace=False)
      (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
      (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
      (activation): GELUActivation()
    )
    (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  )
)
TransformerBlock(
  (attention): DistilBertSdpaAttention(
    (dropout): Dropout(p=0.1, inplace=False)
    (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  )
  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (ffn): FFN(
    (dropout): Dropout(p=0.1, inplace=False)
    (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
    (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
    (activation): GELUActivation()
  )
  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
)
DistilBertSdpaAttention(
  (dropout): Dropout(p=0.1, inplace=False)
  (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
FFN(
  (dropout): Dropout(p=0.1, inplace=False)
  (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
  (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
  (activation): GELUActivation()
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=3072, bias=True)
Linear4bit(in_features=3072, out_features=768, bias=True)
GELUActivation()
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
TransformerBlock(
  (attention): DistilBertSdpaAttention(
    (dropout): Dropout(p=0.1, inplace=False)
    (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  )
  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (ffn): FFN(
    (dropout): Dropout(p=0.1, inplace=False)
    (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
    (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
    (activation): GELUActivation()
  )
  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
)
DistilBertSdpaAttention(
  (dropout): Dropout(p=0.1, inplace=False)
  (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
FFN(
  (dropout): Dropout(p=0.1, inplace=False)
  (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
  (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
  (activation): GELUActivation()
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=3072, bias=True)
Linear4bit(in_features=3072, out_features=768, bias=True)
GELUActivation()
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
TransformerBlock(
  (attention): DistilBertSdpaAttention(
    (dropout): Dropout(p=0.1, inplace=False)
    (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  )
  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (ffn): FFN(
    (dropout): Dropout(p=0.1, inplace=False)
    (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
    (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
    (activation): GELUActivation()
  )
  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
)
DistilBertSdpaAttention(
  (dropout): Dropout(p=0.1, inplace=False)
  (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
FFN(
  (dropout): Dropout(p=0.1, inplace=False)
  (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
  (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
  (activation): GELUActivation()
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=3072, bias=True)
Linear4bit(in_features=3072, out_features=768, bias=True)
GELUActivation()
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
TransformerBlock(
  (attention): DistilBertSdpaAttention(
    (dropout): Dropout(p=0.1, inplace=False)
    (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  )
  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (ffn): FFN(
    (dropout): Dropout(p=0.1, inplace=False)
    (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
    (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
    (activation): GELUActivation()
  )
  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
)
DistilBertSdpaAttention(
  (dropout): Dropout(p=0.1, inplace=False)
  (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
FFN(
  (dropout): Dropout(p=0.1, inplace=False)
  (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
  (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
  (activation): GELUActivation()
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=3072, bias=True)
Linear4bit(in_features=3072, out_features=768, bias=True)
GELUActivation()
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
TransformerBlock(
  (attention): DistilBertSdpaAttention(
    (dropout): Dropout(p=0.1, inplace=False)
    (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  )
  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (ffn): FFN(
    (dropout): Dropout(p=0.1, inplace=False)
    (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
    (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
    (activation): GELUActivation()
  )
  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
)
DistilBertSdpaAttention(
  (dropout): Dropout(p=0.1, inplace=False)
  (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
FFN(
  (dropout): Dropout(p=0.1, inplace=False)
  (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
  (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
  (activation): GELUActivation()
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=3072, bias=True)
Linear4bit(in_features=3072, out_features=768, bias=True)
GELUActivation()
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
TransformerBlock(
  (attention): DistilBertSdpaAttention(
    (dropout): Dropout(p=0.1, inplace=False)
    (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
    (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  )
  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (ffn): FFN(
    (dropout): Dropout(p=0.1, inplace=False)
    (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
    (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
    (activation): GELUActivation()
  )
  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
)
DistilBertSdpaAttention(
  (dropout): Dropout(p=0.1, inplace=False)
  (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)
  (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
Linear4bit(in_features=768, out_features=768, bias=True)
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
FFN(
  (dropout): Dropout(p=0.1, inplace=False)
  (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)
  (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)
  (activation): GELUActivation()
)
Dropout(p=0.1, inplace=False)
Linear4bit(in_features=768, out_features=3072, bias=True)
Linear4bit(in_features=3072, out_features=768, bias=True)
GELUActivation()
LayerNorm((768,), eps=1e-12, elementwise_affine=True)
Linear(in_features=768, out_features=2, bias=True)
Dropout(p=0.1, inplace=False)
c:\Users\CSANADANSYS\anaconda3\Lib\site-packages\trl\trainer\sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 512
  warnings.warn(
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
{'loss': 1.1964, 'grad_norm': 2.6373815536499023, 'learning_rate': 1.919387343812979e-05, 'epoch': 0.12}
{'eval_loss': 1.0556285381317139, 'eval_runtime': 659.7168, 'eval_samples_per_second': 25.07, 'eval_steps_per_second': 1.567, 'epoch': 0.12}
{'loss': 1.1438, 'grad_norm': 3.6368579864501953, 'learning_rate': 1.8387746876259574e-05, 'epoch': 0.24}
{'eval_loss': 1.010238766670227, 'eval_runtime': 659.2553, 'eval_samples_per_second': 25.087, 'eval_steps_per_second': 1.568, 'epoch': 0.24}
