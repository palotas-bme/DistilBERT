{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\CSANADANSYS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db096b2ee270406e937fbd9b2e27dc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8291c407c4348e0aacb13a08fab44b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd10e6ca03d48c09e206c9f75549114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from training_utils import *\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import DistilBertForQuestionAnswering, TrainingArguments, Trainer, DefaultDataCollator, BitsAndBytesConfig\n",
    "from peft import LoraConfig, PeftModel\n",
    "import os\n",
    "import wandb\n",
    "from trl import SFTTrainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "# The MRQA dataset is included in huggingface's datasets library, so we just have to load it\n",
    "# Loading dataset (smaller fraction than in the final becasue had to train on local GPU)\n",
    "mrqa = load_dataset(\"mrqa\", split=\"train[:5%]\")\n",
    "# Creating the train-test-validation split\n",
    "mrqa = mrqa.train_test_split(test_size=0.2)\n",
    "mrqa[\"train\"] = mrqa[\"train\"].train_test_split(test_size=0.2)\n",
    "mrqa[\"val\"] = mrqa[\"train\"][\"test\"]\n",
    "mrqa[\"train\"] = mrqa[\"train\"][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb44d8ccafd14f37821a6dc62f420dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d3fa4c6d3145f08b6d50ecd2c83d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07f3f1e219c4085a4fcc171dace9edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7424364e695541e88784c685f1a59ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "tokenized_mrqa = mrqa.map(preprocess_training_examples, batched=True, \n",
    "                          remove_columns=mrqa[\"train\"].column_names,\n",
    "                          fn_kwargs={\"tokenizer\": tokenizer})\n",
    "tokenized_mrqa.set_format(type=\"torch\")\n",
    "\n",
    "# Tokenizing evaluation dataset\n",
    "tokenized_eval = mrqa[\"test\"].map(preprocess_validation_examples, batched=True, \n",
    "                                  remove_columns=mrqa[\"test\"].column_names,\n",
    "                                  fn_kwargs={\"tokenizer\": tokenizer})\n",
    "tokenized_eval.set_format(type=\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data collator\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "# Configuring parameters for the quantation\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=getattr(torch, \"float16\"),\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "# Configuring parameters of the low-rank adaptation\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=6,\n",
    "    lora_dropout=0.15,\n",
    "    r=2,\n",
    "    bias=\"none\",\n",
    "    task_type=\"QUESTION_ANS\",\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\", \"attention.out_proj\"])\n",
    "\n",
    "# Loading baseline model: DistilBert finetuned on Squadn dataset\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased-distilled-squad\",\n",
    "                                                       quantization_config=bnb_config,\n",
    "                                                       device_map={\"\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ea458b29eb46219cd12ddd4f4078b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e023e568879b48e5a561c6bbd0c96056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match before finetuning: 82.35635519442832\n",
      "F1 score before finetuning: 91.48940098712508, BLEU score before finetuning: 0.7410732358191019\n"
     ]
    }
   ],
   "source": [
    "# Calculating evaluation metrics before further finetuning\n",
    "pre_training_metrics = eval_function(tokenized_eval, model, mrqa[\"test\"])\n",
    "print(f\"Exact match before finetuning: {pre_training_metrics['exact_match']}\\nF1 score before finetuning: {pre_training_metrics['f1']}, BLEU score before finetuning: {pre_training_metrics['bleu']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
